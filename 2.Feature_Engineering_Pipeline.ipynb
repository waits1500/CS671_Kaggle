{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_property_type(property_type):\n",
    "        if \"rental unit\" in property_type:\n",
    "            return \"Rental Unit\"\n",
    "        elif \"tiny\" in property_type or \"Tiny\" in property_type:\n",
    "            return \"Tiny\"\n",
    "        elif \"hotel\" in property_type or \"boutique hotel\" in property_type:\n",
    "            return \"Hotel\"\n",
    "        elif \"condo\" in property_type:\n",
    "            return \"Condo\"\n",
    "        elif \"townhouse\" in property_type:\n",
    "            return \"Townhouse\"\n",
    "        elif \"guest suite\" in property_type or \"guesthouse\" in property_type:\n",
    "            return \"Guesthouse\"\n",
    "        elif \"serviced apartment\" in property_type or \"aparthotel\" in property_type:\n",
    "            return \"Serviced Apartment\"\n",
    "        elif \"vacation home\" in property_type or \"bungalow\" in property_type or \"villa\" in property_type or \"cottage\" in property_type:\n",
    "            return \"Vacation Home\"\n",
    "        elif \"loft\" in property_type:\n",
    "            return \"Loft\"\n",
    "        elif \"hostel\" in property_type:\n",
    "            return \"Hostel\"\n",
    "        elif \"home\" in property_type or \"casa\" in property_type:\n",
    "            return \"Home\"\n",
    "        else:\n",
    "            return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.categorical_cols = None\n",
    "        self.numerical_cols = None\n",
    "        self.special_categorical_cols = ['description','host_since','first_review','last_review','bathrooms_text','amenities','reviews']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # get the object columns\n",
    "        self.numerical_cols = X.select_dtypes(include=[np.number]).columns\n",
    "        self.categorical_cols = X.select_dtypes(include=[object, 'category']).columns.difference(self.special_categorical_cols)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Fill missing values for numerical columns with mean\n",
    "        X[self.numerical_cols] = X[self.numerical_cols].fillna(X[self.numerical_cols].mean())\n",
    "        # Fill missing values for categorical columns with mode\n",
    "        X[self.categorical_cols] = X[self.categorical_cols].fillna(X[self.categorical_cols].mode().iloc[0]).infer_objects()\n",
    "        return X\n",
    "\n",
    "\n",
    "class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=30, random_state=0):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.kmeans_location = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Fit KMeans for location clustering\n",
    "        self.kmeans_location = KMeans(n_clusters=self.n_clusters, random_state=self.random_state).fit(X[['longitude','latitude']])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Copy the dataset to avoid changing the original data\n",
    "        X = X.copy()\n",
    "\n",
    "        # Simplify property type\n",
    "        X['filtered_property_type'] = X['property_type'].apply(summarize_property_type)\n",
    "        X = X.drop(columns=['property_type'])\n",
    "\n",
    "        # 8. Cluster locations using fitted KMeans\n",
    "        X['location'] = self.kmeans_location.predict(X[['longitude','latitude']])\n",
    "\n",
    "        # Process date columns\n",
    "        # for the datatime object, we will replace it with year + month/12, ignoring the day, etc.\n",
    "        # eg. 2019-01-01 will be replaced with 2019 + 1/12 = 2019.0833\n",
    "        date_cols = ['host_since', 'first_review', 'last_review']\n",
    "        for col in date_cols:\n",
    "            X[col] = X[col].dt.year + X[col].dt.month / 12\n",
    "            X[col] = X[col].fillna(0)\n",
    "        # Calculate host duration from 2025\n",
    "        X['host_duration'] = 2025 - X['host_since']\n",
    "\n",
    "        # Extract bathroom features\n",
    "        # Assign 'bathrooms_shared' = 1 if 'shared' is in 'bathrooms_text' and 'bathrooms' > 0, else 0\n",
    "        X['bathrooms_shared'] = X.apply(\n",
    "            lambda row: 1 if ('shared' in str(row['bathrooms_text']).lower() and row['bathrooms'] > 0) else 0,\n",
    "            axis=1)\n",
    "\n",
    "        # Calculate accommodates ratios\n",
    "        # calculate the bedroom, bed, and bathroom per accommodates can get\n",
    "        X['beds_per_accommodates'] = X['beds'] / X['accommodates']\n",
    "        X['bedrooms_per_accommodates'] = X['bedrooms'] / X['accommodates']\n",
    "        X['bathrooms_per_accommodates'] = X['bathrooms'] / X['accommodates']\n",
    "\n",
    "        # Count amenities\n",
    "        X['amenities'] = X['amenities'].apply(ast.literal_eval)\n",
    "        X['amenities_count'] = X['amenities'].apply(len)\n",
    "\n",
    "        # Calculate availability ratios\n",
    "        # Avoid division by zero using numpy where\n",
    "        X['availability_30_ratio'] = np.where(X['availability_60'] == 0, 0, X['availability_30'] / X['availability_60'])\n",
    "        X['availability_60_ratio'] = np.where(X['availability_90'] == 0, 0, X['availability_60'] / X['availability_90'])\n",
    "        X['availability_90_ratio'] = np.where(X['availability_365'] == 0, 0, X['availability_90'] / X['availability_365'])\n",
    "\n",
    "        # Calculate recent review ratios\n",
    "        X['recent_month_review_ratio'] = X.apply(\n",
    "            lambda row: row['number_of_reviews_l30d'] / row['number_of_reviews'] if row['number_of_reviews'] > 0 else 0,\n",
    "            axis=1)\n",
    "        X['recent_year_review_ratio'] = X.apply(\n",
    "            lambda row: row['number_of_reviews_ltm'] / row['number_of_reviews'] if row['number_of_reviews'] > 0 else 0,\n",
    "            axis=1)\n",
    "\n",
    "        # Drop text columns\n",
    "        return X.drop(columns=['name', 'description', 'bathrooms_text', 'amenities', 'reviews'])\n",
    "    \n",
    "class OrdinalEncoderPersonal(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        self.object_cols = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # get the object columns\n",
    "        self.object_cols = X.select_dtypes(include=['object']).columns\n",
    "        self.ordinal_encoder.fit(X[self.object_cols])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.object_cols] = self.ordinal_encoder.transform(X[self.object_cols])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "train_data = pd.read_csv('./Data_Pure/train.csv',parse_dates=['host_since', 'first_review', 'last_review'])\n",
    "train_target = train_data['price'] \n",
    "train_data = train_data.drop('price', axis = 1)\n",
    "\n",
    "test_data = pd.read_csv('./Data_Pure/test.csv',parse_dates=['host_since', 'first_review', 'last_review'])\n",
    "test_id = test_data['id']\n",
    "test_data = test_data.drop('id', axis = 1)\n",
    "\n",
    "# Concatenate the previously processed positive_review_ratio\n",
    "train_review_pos_ratio = pd.read_csv('./Data_Preprocess/train_positive_ratio.csv')\n",
    "test_review_pos_ratio = pd.read_csv('./Data_Preprocess/test_positive_ratio.csv')\n",
    "train_data = pd.concat([train_data,train_review_pos_ratio], axis=1)\n",
    "test_data = pd.concat([test_data, test_review_pos_ratio], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wwwaits\\AppData\\Local\\Temp\\ipykernel_16712\\3542583403.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[self.categorical_cols] = X[self.categorical_cols].fillna(X[self.categorical_cols].mode().iloc[0]).infer_objects()\n",
      "C:\\Users\\wwwaits\\AppData\\Local\\Temp\\ipykernel_16712\\3542583403.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[self.categorical_cols] = X[self.categorical_cols].fillna(X[self.categorical_cols].mode().iloc[0]).infer_objects()\n"
     ]
    }
   ],
   "source": [
    "# define the pipeline\n",
    "feature_engineering_pipeline = Pipeline([\n",
    "    # fill the missing values\n",
    "    ('missing_values', MissingValueTransformer()),\n",
    "    # Apply specific feature engineering\n",
    "    ('feature_engineering', FeatureEngineeringTransformer()),\n",
    "    # Encode object features\n",
    "    ('ordinal_encoder', OrdinalEncoderPersonal())\n",
    "])\n",
    "\n",
    "# Perform the feature engineering\n",
    "train_data = feature_engineering_pipeline.fit_transform(train_data)\n",
    "test_data = feature_engineering_pipeline.transform(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS671",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
